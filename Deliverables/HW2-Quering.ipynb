{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b9127b0",
   "metadata": {},
   "source": [
    "# Querying for decompressed stemmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19399d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from nltk.stem import PorterStemmer\n",
    "import string\n",
    "import math\n",
    "from collections import defaultdict\n",
    "\n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f89d1ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem_text(text, ps):\n",
    "    stemmed = ' '.join([ps.stem(word) for word in text.split()])\n",
    "    return stemmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7bd0cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sw_path = \"../IR_data/AP_DATA/stoplist.txt\"\n",
    "\n",
    "with open(sw_path) as file:\n",
    "    stopwords = file.read().splitlines()\n",
    "\n",
    "additional_stopwords = [\n",
    "    \"document\", \"discuss\", \"system\", \"identifi\", \"actual\", \"ongo\", \"ha\", \"ani\", \"describ\",\n",
    "    \"motiv\", \"directli\",\"successful\", \"detat\", \"area\", \"result\", \"type\", \"anticip\",\"develop\",\n",
    "    \"make\", \"tent\", \"financi\", \"specifi\", \"advanc\", \"someth\", \"standard\", \"fatal\",\n",
    "    \"perpetr\", \"unsubstanti\", \"organ\", \"platform\", \"aid\", \"senior\", \"basi\", \"side\", \n",
    "    \"countri\", \"undesir\", \"good\", \"instanc\", \"method\", \"role\", \"exist\",\n",
    "    \"effort\", \"support\", \"controversi\", \"forc\", \"applic\",\n",
    "    \"determin\", \"second\", \"preliminari\", \"perform\", \"high\", \"tech\", \"predict\", \"insul\", \"instal\", \"regul\", \"level\",\n",
    "    \"country\", \"dual-us\", \"militari\", \"alleg\", \"polit\", \"candid\", \"reserv\", \"contract\", \"fail\", \"state\", \n",
    "    \"concern\", \"manufactur\", \"current\", \"product\", \"equip\", \"non\", \"take\", \"fine\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e73a62af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_content(text):\n",
    "    text = text.translate(str.maketrans(\"\", \"\", \",.()'\\\"\"))\n",
    "    text = text.replace(\"-\", \" \")\n",
    "    words = text.split()\n",
    "    processed_words = []\n",
    "    for word in words:\n",
    "        processed_words.append(word.lower() if word.lower() not in stopwords else '')\n",
    "    processed_text = ' '.join(processed_words)\n",
    "    return processed_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1240b922",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_additional_stopwords(text):\n",
    "    text = ' '.join([word.lower() for word in text.split() if word.lower() not in additional_stopwords])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "129e582b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_preprocessing(query):\n",
    "    query = process_content(query)\n",
    "    query = stem_text(query, ps)\n",
    "    query = remove_additional_stopwords(query)\n",
    "    return query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da584646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{85: 'corrupt public offici', 59: 'weather least locat', 56: 'prime lend rate prime rate', 71: 'incurs border guerrilla', 64: 'hostag', 62: 'coup attempt', 93: 'nation rifl associ nra', 99: 'iran contra affair', 58: 'rail strike rail strike', 77: 'poach wildlif', 54: 'agreement launch commerci satellit', 87: 'offic institut', 94: 'crime comput', 100: 'communist transfer technolog nation', 89: 'invest opec downstream', 61: 'israel iran contra affair', 95: 'comput crime', 68: 'safeti worker diamet fiber', 57: 'mci bell', 97: 'fiber optic technolog', 98: 'fiber optic', 60: 'salari incent pay pay', 80: '1988 presidenti', 63: 'machin translat', 91: 'weapon'}\n"
     ]
    }
   ],
   "source": [
    "query_dict = {}\n",
    "query_file_path = \"../IR_data/AP_DATA/query_desc.51-100.short.txt\"\n",
    "\n",
    "with open(query_file_path, 'r') as query_desc_file:\n",
    "    queries = query_desc_file.readlines()\n",
    "\n",
    "for query_desc in queries:\n",
    "    query_desc = query_desc.strip()\n",
    "\n",
    "    if not query_desc:\n",
    "        continue\n",
    "\n",
    "    query_num, query_text = query_desc.split('.', 1)\n",
    "    query_num = int(query_num.strip())\n",
    "    query_text = query_preprocessing(query_text.strip())\n",
    "\n",
    "    query_dict[query_num] = query_text\n",
    "\n",
    "print(query_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87c10424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['corrupt', 'public', 'offici', 'weather', 'least', 'locat', 'prime', 'lend', 'rate', 'prime', 'rate', 'incurs', 'border', 'guerrilla', 'hostag', 'coup', 'attempt', 'nation', 'rifl', 'associ', 'nra', 'iran', 'contra', 'affair', 'rail', 'strike', 'rail', 'strike', 'poach', 'wildlif', 'agreement', 'launch', 'commerci', 'satellit', 'offic', 'institut', 'crime', 'comput', 'communist', 'transfer', 'technolog', 'nation', 'invest', 'opec', 'downstream', 'israel', 'iran', 'contra', 'affair', 'comput', 'crime', 'safeti', 'worker', 'diamet', 'fiber', 'mci', 'bell', 'fiber', 'optic', 'technolog', 'fiber', 'optic', 'salari', 'incent', 'pay', 'pay', '1988', 'presidenti', 'machin', 'translat', 'weapon']\n"
     ]
    }
   ],
   "source": [
    "all_query_terms = []\n",
    "\n",
    "for text in query_dict.values():\n",
    "    all_query_terms.extend(text.split())\n",
    "\n",
    "print(all_query_terms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a987f8",
   "metadata": {},
   "source": [
    "# Read doc_map and store it in a dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01db8173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc_map read successfully from doc_map.txt file.\n",
      "84678\n"
     ]
    }
   ],
   "source": [
    "doc_map_file_path = \"./stemmed_index_files/doc_map.txt\"\n",
    "all_document_ids = {}\n",
    "\n",
    "with open(doc_map_file_path, 'r') as doc_map_file:\n",
    "    for line in doc_map_file:\n",
    "        parts = line.strip().split(': ')\n",
    "        if len(parts) == 2:\n",
    "            value, doc_id = parts\n",
    "            all_document_ids[doc_id] = value\n",
    "\n",
    "print(\"Doc_map read successfully from doc_map.txt file.\")\n",
    "print(len(all_document_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c249f66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document lengths read successfully from tokenized_dict_stemmed_length_map.txt file.\n",
      "Total document count: 84678\n",
      "Average document length: 253.7629844823921\n"
     ]
    }
   ],
   "source": [
    "total_length = 0\n",
    "total_docs = 0\n",
    "document_lengths = {}\n",
    "\n",
    "with open(\"./stemmed_index_files/tokenized_dict_stemmed_length_map.txt\", \"r\") as file:\n",
    "    for line in file:\n",
    "        parts = line.strip().split()\n",
    "        if len(parts) == 2:\n",
    "            doc_id, length = parts\n",
    "            length = int(length)\n",
    "            document_lengths[doc_id] = length\n",
    "            total_length += length\n",
    "            total_docs += 1\n",
    "\n",
    "avg_doc_length = total_length / total_docs\n",
    "\n",
    "print(\"Document lengths read successfully from tokenized_dict_stemmed_length_map.txt file.\")\n",
    "print(\"Total document count:\", total_docs)\n",
    "print(\"Average document length:\", avg_doc_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21738d9f",
   "metadata": {},
   "source": [
    "# Get the postings using binary search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f818d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_search(query, catalog_file_path):\n",
    "    with open(catalog_file_path, 'r') as catalog_file:\n",
    "        lines = catalog_file.readlines()\n",
    "\n",
    "        results = {}\n",
    "        for term in query:\n",
    "            low = 0\n",
    "            high = len(lines) - 1\n",
    "\n",
    "            while low <= high:\n",
    "                mid = (low + high) // 2\n",
    "                current_term, offset, size = lines[mid].strip().split()\n",
    "\n",
    "                if current_term == term:\n",
    "                    results[term] = (mid, lines[mid])\n",
    "                    break\n",
    "                elif current_term < term:\n",
    "                    low = mid + 1\n",
    "                else:\n",
    "                    high = mid - 1\n",
    "\n",
    "            if term not in results:\n",
    "                results[term] = -1\n",
    "\n",
    "    return results\n",
    "\n",
    "def read_data_from_index_file(offset, size, index_file_path):\n",
    "    data = \"\"\n",
    "    with open(index_file_path, 'r') as index_file:\n",
    "        index_file.seek(offset)\n",
    "        data = index_file.read(size)\n",
    "    return data\n",
    "\n",
    "def process_query(query, catalog_file_path, index_file_path):\n",
    "    term_data_dict = {}\n",
    "    \n",
    "    catalog_file_info_query_terms = binary_search(query, catalog_file_path)\n",
    "\n",
    "    for term, (position, line) in catalog_file_info_query_terms.items():\n",
    "        if position != -1:\n",
    "            term, offset, size = line.strip().split()\n",
    "            data = read_data_from_index_file(int(offset), int(size), index_file_path)\n",
    "            term_data_dict[term] = data\n",
    "\n",
    "    return term_data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c470fa71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Term data dictionary created.\n"
     ]
    }
   ],
   "source": [
    "catalog_file_path = './stemmed_index_files/final_merged_catalog_file.txt'\n",
    "index_file_path = './stemmed_index_files/final_merged_index_file.txt'\n",
    "\n",
    "term_data_dict = process_query(all_query_terms, catalog_file_path, index_file_path)\n",
    "print(\"Term data dictionary created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4824653d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def update_term_data_dict(term_data_dict):\n",
    "    updated_dict = {}\n",
    "    for key, value in term_data_dict.items():\n",
    "        positions = {}\n",
    "        matches = re.findall(r'(\\d+):(\\[.*?\\])', value)\n",
    "        for match in matches:\n",
    "            doc_id = int(match[0])\n",
    "            pos_str = match[1]\n",
    "            positions[doc_id] = [int(pos) for pos in pos_str[1:-1].split(',')]\n",
    "\n",
    "        df = len(positions)\n",
    "\n",
    "        updated_dict[key] = {'positions': positions, 'doc_freq': df}\n",
    "    return updated_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1bb5faaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_document_term_vectors = update_term_data_dict(term_data_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75fca779",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ebcaeb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_okapi_tf_tfidf(tf, length_doc, avg_doc_length):\n",
    "    return tf / (tf + 0.5 + 1.5 * (length_doc / avg_doc_length))\n",
    "\n",
    "def calculate_idf(dfw, total_documents):\n",
    "    return math.log(total_documents / dfw)\n",
    "\n",
    "def calculate_tfidf(tf, length_doc, avg_doc_length, dfw, total_documents):\n",
    "    okapi_tf_score = calculate_okapi_tf_tfidf(tf, length_doc, avg_doc_length)\n",
    "    idf_score = calculate_idf(dfw, total_documents)\n",
    "    return okapi_tf_score * idf_score\n",
    "\n",
    "def run_queries_and_write_results_tfidf(output_file, query_dict, all_document_term_vectors):\n",
    "    with open(output_file, 'w') as output:\n",
    "        for query_num, query_text in query_dict.items():\n",
    "            print(f\"Processing Query {query_num}: {query_text}\")\n",
    "\n",
    "            query_terms = query_text.split()\n",
    "            document_scores = defaultdict(float)\n",
    "            \n",
    "            for term in query_terms:\n",
    "                if term in all_document_term_vectors:\n",
    "                    document_term_vector = all_document_term_vectors[term]\n",
    "                    dfw = document_term_vector['doc_freq']\n",
    "                    avg_doc_length = sum(document_lengths.values()) / len(document_lengths)\n",
    "                    \n",
    "                    for doc_id, positions in document_term_vector['positions'].items():\n",
    "                        tf = len(positions)\n",
    "                        length_doc = document_lengths[all_document_ids[str(doc_id)]]\n",
    "                        \n",
    "                        tfidf_score = calculate_tfidf(tf, length_doc, avg_doc_length, dfw, total_docs)\n",
    "                        document_scores[doc_id] += tfidf_score\n",
    "\n",
    "            sorted_docs = sorted(document_scores.items(), key=lambda x: x[1], reverse=True)[:1000]\n",
    "\n",
    "            for rank, (doc_id, score) in enumerate(sorted_docs, start=1):\n",
    "                output.write(str(query_num) + ' Q0 ' + str(all_document_ids[str(doc_id)]) + ' ' + str(rank) + ' ' + str(score) + ' Exp'+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b621d04e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Query 85: corrupt public offici\n",
      "Processing Query 59: weather least locat\n",
      "Processing Query 56: prime lend rate prime rate\n",
      "Processing Query 71: incurs border guerrilla\n",
      "Processing Query 64: hostag\n",
      "Processing Query 62: coup attempt\n",
      "Processing Query 93: nation rifl associ nra\n",
      "Processing Query 99: iran contra affair\n",
      "Processing Query 58: rail strike rail strike\n",
      "Processing Query 77: poach wildlif\n",
      "Processing Query 54: agreement launch commerci satellit\n",
      "Processing Query 87: offic institut\n",
      "Processing Query 94: crime comput\n",
      "Processing Query 100: communist transfer technolog nation\n",
      "Processing Query 89: invest opec downstream\n",
      "Processing Query 61: israel iran contra affair\n",
      "Processing Query 95: comput crime\n",
      "Processing Query 68: safeti worker diamet fiber\n",
      "Processing Query 57: mci bell\n",
      "Processing Query 97: fiber optic technolog\n",
      "Processing Query 98: fiber optic\n",
      "Processing Query 60: salari incent pay pay\n",
      "Processing Query 80: 1988 presidenti\n",
      "Processing Query 63: machin translat\n",
      "Processing Query 91: weapon\n",
      "Queries executed successfully.\n"
     ]
    }
   ],
   "source": [
    "output_file_path = \"./result_files/output_TFIDF_Score.txt\"\n",
    "run_queries_and_write_results_tfidf(output_file_path, query_dict, all_document_term_vectors)\n",
    "print(\"Queries executed successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd1caec",
   "metadata": {},
   "source": [
    "# BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1749d8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from collections import defaultdict\n",
    "\n",
    "def calculate_okapi_bm25(tfwd, dfw, D, length_doc, avg_doc_length, tfwq, k1=1.2, b=0.75, k2=100):\n",
    "    term1 = math.log((D - dfw + 0.5) / (dfw + 0.5))\n",
    "    term2_num = (tfwd * (k1 + 1))\n",
    "    term2_den = (tfwd + k1 * ((1 - b) + (b * (length_doc / avg_doc_length))))\n",
    "    term3 = (tfwq + (k2 * tfwq)) / (tfwq + k2)\n",
    "    return term1 * (term2_num / term2_den) * term3\n",
    "\n",
    "def run_queries_and_write_results_bm25(output_file, query_dict, all_document_term_vectors):\n",
    "    with open(output_file, 'w') as output:\n",
    "        for query_num, query_text in query_dict.items():\n",
    "            print(f\"Processing Query {query_num}: {query_text}\")\n",
    "\n",
    "            query_terms = query_text.split()\n",
    "            D = len(all_document_ids)  \n",
    "            document_scores = defaultdict(float)\n",
    "\n",
    "            for term in query_terms:\n",
    "                if term in all_document_term_vectors:\n",
    "                    document_term_vector = all_document_term_vectors[term]\n",
    "                    dfw = document_term_vector['doc_freq']\n",
    "                    avg_doc_length = sum(document_lengths.values()) / len(document_lengths)\n",
    "                    \n",
    "                    for doc_id, positions in document_term_vector['positions'].items():\n",
    "                        tfwd = len(positions)\n",
    "                        length_doc = document_lengths[all_document_ids[str(doc_id)]]\n",
    "                        tfwq = query_terms.count(term)\n",
    "                        \n",
    "                        bm25_score = calculate_okapi_bm25(tfwd, dfw, D, length_doc, avg_doc_length, tfwq)\n",
    "                        document_scores[doc_id] += bm25_score\n",
    "\n",
    "            sorted_docs = sorted(document_scores.items(), key=lambda x: x[1], reverse=True)[:1000]\n",
    "\n",
    "            for rank, (doc_id, score) in enumerate(sorted_docs, start=1):\n",
    "                output.write(str(query_num) + ' Q0 ' + str(all_document_ids[str(doc_id)]) + ' ' + str(rank) + ' ' + str(score) + ' Exp'+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c4785d10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Query 85: corrupt public offici\n",
      "Processing Query 59: weather least locat\n",
      "Processing Query 56: prime lend rate prime rate\n",
      "Processing Query 71: incurs border guerrilla\n",
      "Processing Query 64: hostag\n",
      "Processing Query 62: coup attempt\n",
      "Processing Query 93: nation rifl associ nra\n",
      "Processing Query 99: iran contra affair\n",
      "Processing Query 58: rail strike rail strike\n",
      "Processing Query 77: poach wildlif\n",
      "Processing Query 54: agreement launch commerci satellit\n",
      "Processing Query 87: offic institut\n",
      "Processing Query 94: crime comput\n",
      "Processing Query 100: communist transfer technolog nation\n",
      "Processing Query 89: invest opec downstream\n",
      "Processing Query 61: israel iran contra affair\n",
      "Processing Query 95: comput crime\n",
      "Processing Query 68: safeti worker diamet fiber\n",
      "Processing Query 57: mci bell\n",
      "Processing Query 97: fiber optic technolog\n",
      "Processing Query 98: fiber optic\n",
      "Processing Query 60: salari incent pay pay\n",
      "Processing Query 80: 1988 presidenti\n",
      "Processing Query 63: machin translat\n",
      "Processing Query 91: weapon\n",
      "Queries executed successfully.\n"
     ]
    }
   ],
   "source": [
    "output_file_path = \"./result_files/output_BM25_Score.txt\"\n",
    "run_queries_and_write_results_bm25(output_file_path, query_dict, all_document_term_vectors)\n",
    "print(\"Queries executed successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f3888ea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "217712\n"
     ]
    }
   ],
   "source": [
    "catalog_file_path = './stemmed_index_files/final_merged_catalog_file.txt'\n",
    "\n",
    "with open(catalog_file_path, 'r') as catalog_file:\n",
    "        total_unique_terms = sum(1 for line in catalog_file)\n",
    "\n",
    "print(total_unique_terms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d52fa5",
   "metadata": {},
   "source": [
    "# Unigram Laplace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e0e6de4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_laplace_score(tfwd, length_doc, total_unique_terms):\n",
    "    return math.log((tfwd + 1) / (length_doc + total_unique_terms))\n",
    "\n",
    "def run_queries_and_write_results_laplace(output_file, query_dict, total_unique_terms, all_document_term_vectors):\n",
    "    with open(output_file, 'w') as output:\n",
    "        document_scores = defaultdict(float)\n",
    "\n",
    "        for query_num, query_text in query_dict.items():\n",
    "            print(f\"Processing Query {query_num}: {query_text}\")\n",
    "            query_terms = query_text.split()\n",
    "            for doc_id in all_document_ids:\n",
    "                document_scores[doc_id] = 1000\n",
    "            for term in query_terms:\n",
    "                for doc_id in all_document_ids:\n",
    "                    if term in all_document_term_vectors and int(doc_id) in all_document_term_vectors[term]['positions']:\n",
    "                        tf = len(all_document_term_vectors[term]['positions'][int(doc_id)])\n",
    "                        length_doc = document_lengths[all_document_ids[str(doc_id)]]\n",
    "                        laplace_score = calculate_laplace_score(tf, length_doc, total_unique_terms)\n",
    "                        document_scores[doc_id] += laplace_score\n",
    "                    else:\n",
    "                        document_scores[doc_id] -= 1000\n",
    "            \n",
    "            sorted_docs = sorted(document_scores.items(), key=lambda x: x[1], reverse=True)[:1000]\n",
    "\n",
    "            for rank, (doc_id, score) in enumerate(sorted_docs, start=1):\n",
    "                output.write(str(query_num) + ' Q0 ' + str(all_document_ids[str(doc_id)]) + ' ' + str(rank) + ' ' + str(score) + ' Exp'+\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "afb77782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Query 85: corrupt public offici\n",
      "Processing Query 59: weather least locat\n",
      "Processing Query 56: prime lend rate prime rate\n",
      "Processing Query 71: incurs border guerrilla\n",
      "Processing Query 64: hostag\n",
      "Processing Query 62: coup attempt\n",
      "Processing Query 93: nation rifl associ nra\n",
      "Processing Query 99: iran contra affair\n",
      "Processing Query 58: rail strike rail strike\n",
      "Processing Query 77: poach wildlif\n",
      "Processing Query 54: agreement launch commerci satellit\n",
      "Processing Query 87: offic institut\n",
      "Processing Query 94: crime comput\n",
      "Processing Query 100: communist transfer technolog nation\n",
      "Processing Query 89: invest opec downstream\n",
      "Processing Query 61: israel iran contra affair\n",
      "Processing Query 95: comput crime\n",
      "Processing Query 68: safeti worker diamet fiber\n",
      "Processing Query 57: mci bell\n",
      "Processing Query 97: fiber optic technolog\n",
      "Processing Query 98: fiber optic\n",
      "Processing Query 60: salari incent pay pay\n",
      "Processing Query 80: 1988 presidenti\n",
      "Processing Query 63: machin translat\n",
      "Processing Query 91: weapon\n",
      "Queries executed successfully.\n"
     ]
    }
   ],
   "source": [
    "output_file_path = \"./result_files/output_UnigramLaplace_Score.txt\"\n",
    "run_queries_and_write_results_laplace(output_file_path, query_dict, total_unique_terms, all_document_term_vectors)\n",
    "print(\"Queries executed successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21bb618",
   "metadata": {},
   "source": [
    "# Querying for decompressed unstemmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0e9e805c",
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_stopwords_unstemmed = [\n",
    "    \"document\", \"discuss\", \"system\", \"identifi\", \"actual\", \"ongoing\", \"ha\", \"ani\", \"describ\",\"states\",\n",
    "    \"motiv\", \"directli\",\"successful\", \"detat\", \"area\", \"result\", \"type\", \"anticip\",\"development\",\n",
    "    \"make\", \"tent\", \"financi\", \"specifi\", \"advanc\", \"someth\", \"standard\", \"fatality\",\n",
    "    \"perpetr\", \"unsubstanti\", \"organ\", \"platform\", \"aid\", \"senior\", \"basi\", \"side\", \n",
    "    \"countri\", \"undesir\", \"goods\", \"instanc\", \"method\", \"role\", \"exist\",\n",
    "    \"effort\", \"supporters\", \"controversi\", \"forces\", \"applic\",\n",
    "    \"determin\", \"second\", \"preliminari\", \"perform\", \"high\", \"tech\", \"predict\", \"insul\", \"instal\", \"regul\", \"level\",\n",
    "    \"country\", \"dual-us\", \"military\", \"allegations\", \"politically\", \"candid\", \"reservation\", \"contract\", \"failed\", \"state\", \n",
    "    \"concern\", \"manufactur\", \"current\", \"product\", \"equip\", \"non\", \"taking\", \"fine\", \"application\", \"concerns\", \"manufacturing\",\n",
    "    \"products\", \"equipment\", \"performance\", \"candidate\", \"systems\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "74170431",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_additional_stopwords_unstemmed(text):\n",
    "    text = ' '.join([word.lower() for word in text.split() if word.lower() not in additional_stopwords_unstemmed])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "15cafcbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_preprocessing_unstemmed(query):\n",
    "    query = process_content(query)\n",
    "    query = remove_additional_stopwords_unstemmed(query)\n",
    "    return query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6d79f377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{85: 'corrupt public officials', 59: 'weather least location', 56: 'prime lending rate prime rate', 71: 'incursions border guerrilla', 64: 'hostage', 62: 'coup attempted', 93: 'national rifle association nra', 99: 'iran contra affair', 58: 'rail strike rail strike', 77: 'poaching wildlife', 54: 'agreement launch commercial satellite', 87: 'officers institution', 94: 'crime computer', 100: 'communist transfer technologies nations', 89: 'investment opec downstream', 61: 'israel iran contra affair', 95: 'computer crime', 68: 'safety workers diameter fibers', 57: 'mci bell', 97: 'fiber optics technology', 98: 'fiber optics', 60: 'salary incentive pay pay', 80: '1988 presidential', 63: 'machine translation', 91: 'weapons'}\n"
     ]
    }
   ],
   "source": [
    "query_dict_unstemmed = {}\n",
    "query_file_path = \"../IR_data/AP_DATA/query_desc.51-100.short.txt\"\n",
    "\n",
    "with open(query_file_path, 'r') as query_desc_file:\n",
    "    queries = query_desc_file.readlines()\n",
    "\n",
    "for query_desc in queries:\n",
    "    query_desc = query_desc.strip()\n",
    "\n",
    "    if not query_desc:\n",
    "        continue\n",
    "\n",
    "    query_num, query_text = query_desc.split('.', 1)\n",
    "    query_num = int(query_num.strip())\n",
    "    query_text = query_preprocessing_unstemmed(query_text.strip())\n",
    "\n",
    "    query_dict_unstemmed[query_num] = query_text\n",
    "\n",
    "print(query_dict_unstemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8a4f9814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['corrupt', 'public', 'officials', 'weather', 'least', 'location', 'prime', 'lending', 'rate', 'prime', 'rate', 'incursions', 'border', 'guerrilla', 'hostage', 'coup', 'attempted', 'national', 'rifle', 'association', 'nra', 'iran', 'contra', 'affair', 'rail', 'strike', 'rail', 'strike', 'poaching', 'wildlife', 'agreement', 'launch', 'commercial', 'satellite', 'officers', 'institution', 'crime', 'computer', 'communist', 'transfer', 'technologies', 'nations', 'investment', 'opec', 'downstream', 'israel', 'iran', 'contra', 'affair', 'computer', 'crime', 'safety', 'workers', 'diameter', 'fibers', 'mci', 'bell', 'fiber', 'optics', 'technology', 'fiber', 'optics', 'salary', 'incentive', 'pay', 'pay', '1988', 'presidential', 'machine', 'translation', 'weapons']\n"
     ]
    }
   ],
   "source": [
    "all_query_terms_unstemmed = []\n",
    "\n",
    "for text in query_dict_unstemmed.values():\n",
    "    all_query_terms_unstemmed.extend(text.split())\n",
    "\n",
    "print(all_query_terms_unstemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a55fa001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document lengths read successfully from tokenized_dict_non_stemmed_length_map.txt file.\n",
      "Total document count: 84678\n",
      "Average document length: 253.7629844823921\n"
     ]
    }
   ],
   "source": [
    "total_length = 0\n",
    "total_docs = 0\n",
    "document_lengths = {}\n",
    "\n",
    "with open(\"./non_stemmed_index_files/tokenized_dict_non_stemmed_length_map.txt\", \"r\") as file:\n",
    "    for line in file:\n",
    "        parts = line.strip().split()\n",
    "        if len(parts) == 2:\n",
    "            doc_id, length = parts\n",
    "            length = int(length)\n",
    "            document_lengths[doc_id] = length\n",
    "            total_length += length\n",
    "            total_docs += 1\n",
    "\n",
    "avg_doc_length = total_length / total_docs\n",
    "\n",
    "print(\"Document lengths read successfully from tokenized_dict_non_stemmed_length_map.txt file.\")\n",
    "print(\"Total document count:\", total_docs)\n",
    "print(\"Average document length:\", avg_doc_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e5f165b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Term data dictionary created.\n"
     ]
    }
   ],
   "source": [
    "catalog_file_path_unstemmed = './non_stemmed_index_files/final_merged_catalog_file.txt'\n",
    "index_file_path_unstemmed = './non_stemmed_index_files/final_merged_index_file.txt'\n",
    "\n",
    "term_data_dict_unstemmed = process_query(all_query_terms_unstemmed, catalog_file_path_unstemmed, index_file_path_unstemmed)\n",
    "print(\"Term data dictionary created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1395c3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_document_term_vectors_unstemmed = update_term_data_dict(term_data_dict_unstemmed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b91a730",
   "metadata": {},
   "source": [
    "# Unstemmed TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "762ac36b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Query 85: corrupt public officials\n",
      "Processing Query 59: weather least location\n",
      "Processing Query 56: prime lending rate prime rate\n",
      "Processing Query 71: incursions border guerrilla\n",
      "Processing Query 64: hostage\n",
      "Processing Query 62: coup attempted\n",
      "Processing Query 93: national rifle association nra\n",
      "Processing Query 99: iran contra affair\n",
      "Processing Query 58: rail strike rail strike\n",
      "Processing Query 77: poaching wildlife\n",
      "Processing Query 54: agreement launch commercial satellite\n",
      "Processing Query 87: officers institution\n",
      "Processing Query 94: crime computer\n",
      "Processing Query 100: communist transfer technologies nations\n",
      "Processing Query 89: investment opec downstream\n",
      "Processing Query 61: israel iran contra affair\n",
      "Processing Query 95: computer crime\n",
      "Processing Query 68: safety workers diameter fibers\n",
      "Processing Query 57: mci bell\n",
      "Processing Query 97: fiber optics technology\n",
      "Processing Query 98: fiber optics\n",
      "Processing Query 60: salary incentive pay pay\n",
      "Processing Query 80: 1988 presidential\n",
      "Processing Query 63: machine translation\n",
      "Processing Query 91: weapons\n",
      "Queries executed successfully.\n"
     ]
    }
   ],
   "source": [
    "output_file_path = \"./result_files/output_TFIDF_Unstemmed_Score.txt\"\n",
    "run_queries_and_write_results_tfidf(output_file_path, query_dict_unstemmed, all_document_term_vectors_unstemmed)\n",
    "print(\"Queries executed successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dfa7480",
   "metadata": {},
   "source": [
    "# Unstemmed BM-25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7a75be4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Query 85: corrupt public officials\n",
      "Processing Query 59: weather least location\n",
      "Processing Query 56: prime lending rate prime rate\n",
      "Processing Query 71: incursions border guerrilla\n",
      "Processing Query 64: hostage\n",
      "Processing Query 62: coup attempted\n",
      "Processing Query 93: national rifle association nra\n",
      "Processing Query 99: iran contra affair\n",
      "Processing Query 58: rail strike rail strike\n",
      "Processing Query 77: poaching wildlife\n",
      "Processing Query 54: agreement launch commercial satellite\n",
      "Processing Query 87: officers institution\n",
      "Processing Query 94: crime computer\n",
      "Processing Query 100: communist transfer technologies nations\n",
      "Processing Query 89: investment opec downstream\n",
      "Processing Query 61: israel iran contra affair\n",
      "Processing Query 95: computer crime\n",
      "Processing Query 68: safety workers diameter fibers\n",
      "Processing Query 57: mci bell\n",
      "Processing Query 97: fiber optics technology\n",
      "Processing Query 98: fiber optics\n",
      "Processing Query 60: salary incentive pay pay\n",
      "Processing Query 80: 1988 presidential\n",
      "Processing Query 63: machine translation\n",
      "Processing Query 91: weapons\n",
      "Queries executed successfully.\n"
     ]
    }
   ],
   "source": [
    "output_file_path = \"./result_files/output_BM25_Unstemmed_Score.txt\"\n",
    "run_queries_and_write_results_bm25(output_file_path, query_dict_unstemmed, all_document_term_vectors_unstemmed)\n",
    "print(\"Queries executed successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40d6973",
   "metadata": {},
   "source": [
    "# Unstemmed Unigram Laplace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1adf57bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "271747\n",
      "Processing Query 85: corrupt public officials\n",
      "Processing Query 59: weather least location\n",
      "Processing Query 56: prime lending rate prime rate\n",
      "Processing Query 71: incursions border guerrilla\n",
      "Processing Query 64: hostage\n",
      "Processing Query 62: coup attempted\n",
      "Processing Query 93: national rifle association nra\n",
      "Processing Query 99: iran contra affair\n",
      "Processing Query 58: rail strike rail strike\n",
      "Processing Query 77: poaching wildlife\n",
      "Processing Query 54: agreement launch commercial satellite\n",
      "Processing Query 87: officers institution\n",
      "Processing Query 94: crime computer\n",
      "Processing Query 100: communist transfer technologies nations\n",
      "Processing Query 89: investment opec downstream\n",
      "Processing Query 61: israel iran contra affair\n",
      "Processing Query 95: computer crime\n",
      "Processing Query 68: safety workers diameter fibers\n",
      "Processing Query 57: mci bell\n",
      "Processing Query 97: fiber optics technology\n",
      "Processing Query 98: fiber optics\n",
      "Processing Query 60: salary incentive pay pay\n",
      "Processing Query 80: 1988 presidential\n",
      "Processing Query 63: machine translation\n",
      "Processing Query 91: weapons\n",
      "Queries executed successfully.\n"
     ]
    }
   ],
   "source": [
    "catalog_file_path = './non_stemmed_index_files/final_merged_catalog_file.txt'\n",
    "\n",
    "with open(catalog_file_path, 'r') as catalog_file:\n",
    "        total_unique_terms_unstemmed = sum(1 for line in catalog_file)\n",
    "\n",
    "print(total_unique_terms_unstemmed)\n",
    "\n",
    "output_file_path = \"./result_files/output_UnigramLaplace_Unstemmed_Score.txt\"\n",
    "run_queries_and_write_results_laplace(output_file_path, query_dict_unstemmed, total_unique_terms_unstemmed, all_document_term_vectors_unstemmed)\n",
    "print(\"Queries executed successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fea4c16",
   "metadata": {},
   "source": [
    "# Compressed index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b9e9b3b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Term data dictionary created.\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "\n",
    "def read_data_from_index_file_compressed(offset, size, index_file_path):\n",
    "    data = b\"\"\n",
    "    with gzip.open(index_file_path, 'rb') as index_file:\n",
    "        index_file.seek(offset)\n",
    "        data = index_file.read(size)\n",
    "    return data.decode('utf-8')\n",
    "\n",
    "def process_query_compressed(all_query_terms, catalog_file_path, index_file_path):\n",
    "    term_data_dict = {}\n",
    "    \n",
    "    catalog_file_info_query_terms = binary_search(all_query_terms, catalog_file_path)\n",
    "\n",
    "    for term, (position, line) in catalog_file_info_query_terms.items():\n",
    "        if position != -1:\n",
    "            _, offset, size = line.strip().split()\n",
    "            data = read_data_from_index_file_compressed(int(offset), int(size), index_file_path)\n",
    "            term_data_dict[term] = data\n",
    "\n",
    "    return term_data_dict\n",
    "\n",
    "\n",
    "catalog_file_path = './stemmed_index_files/final_merged_catalog_file.txt'\n",
    "index_file_path_compressed = './stemmed_index_files/final_merged_index_file.gz'\n",
    "\n",
    "term_data_dict_compressed = process_query_compressed(all_query_terms, catalog_file_path, index_file_path_compressed)\n",
    "print(\"Term data dictionary created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ec9a529f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_document_term_vectors_compressed = update_term_data_dict(term_data_dict_compressed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f914f861",
   "metadata": {},
   "source": [
    "# BM-25 using one compressed index file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "77002ae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Query 85: corrupt public offici\n",
      "Processing Query 59: weather least locat\n",
      "Processing Query 56: prime lend rate prime rate\n",
      "Processing Query 71: incurs border guerrilla\n",
      "Processing Query 64: hostag\n",
      "Processing Query 62: coup attempt\n",
      "Processing Query 93: nation rifl associ nra\n",
      "Processing Query 99: iran contra affair\n",
      "Processing Query 58: rail strike rail strike\n",
      "Processing Query 77: poach wildlif\n",
      "Processing Query 54: agreement launch commerci satellit\n",
      "Processing Query 87: offic institut\n",
      "Processing Query 94: crime comput\n",
      "Processing Query 100: communist transfer technolog nation\n",
      "Processing Query 89: invest opec downstream\n",
      "Processing Query 61: israel iran contra affair\n",
      "Processing Query 95: comput crime\n",
      "Processing Query 68: safeti worker diamet fiber\n",
      "Processing Query 57: mci bell\n",
      "Processing Query 97: fiber optic technolog\n",
      "Processing Query 98: fiber optic\n",
      "Processing Query 60: salari incent pay pay\n",
      "Processing Query 80: 1988 presidenti\n",
      "Processing Query 63: machin translat\n",
      "Processing Query 91: weapon\n",
      "Queries executed successfully.\n"
     ]
    }
   ],
   "source": [
    "output_file_path = \"./result_files/output_BM25_Compressed_Score.txt\"\n",
    "run_queries_and_write_results_bm25(output_file_path, query_dict, all_document_term_vectors_compressed)\n",
    "print(\"Queries executed successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0e0024",
   "metadata": {},
   "source": [
    "# Decompression using of compressed chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0229b2bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compressed chunks: \n",
      "{'chesebroughpond': {'file_path': './stemmed_index_files/compressed_index_files/chunk_1_compressed.gz', 'file_offset': 0}, 'motionless': {'file_path': './stemmed_index_files/compressed_index_files/chunk_2_compressed.gz', 'file_offset': 35891995}, 'zzzz': {'file_path': './stemmed_index_files/compressed_index_files/chunk_3_compressed.gz', 'file_offset': 111511981}}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "input_file_path = \"./stemmed_index_files/compressed_chunks.json\"\n",
    "with open(input_file_path, 'r') as input_file:\n",
    "    compressed_chunks = json.load(input_file)\n",
    "\n",
    "print(\"Compressed chunks: \")\n",
    "print(compressed_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3467da32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "term_data_dict_compressed created\n"
     ]
    }
   ],
   "source": [
    "def read_data_from_index_file_compressed(offset, size, index_file_path):\n",
    "    data = b\"\"\n",
    "    with gzip.open(index_file_path, 'rb') as index_file:\n",
    "        index_file.seek(offset)\n",
    "        data = index_file.read(size)\n",
    "    return data.decode('utf-8')\n",
    "\n",
    "def process_query_compressed(all_query_terms, catalog_file_path, index_file_paths):\n",
    "    term_data_dict = {}\n",
    "    \n",
    "    catalog_file_info_query_terms = binary_search(all_query_terms, catalog_file_path)\n",
    "\n",
    "    for term, (position, line) in catalog_file_info_query_terms.items():\n",
    "        if position != -1:\n",
    "            term, offset, size = line.strip().split()\n",
    "            offset = int(offset)\n",
    "            size = int(size)\n",
    "            \n",
    "            compresssed_chunk_key = None\n",
    "            for chunk_key, (file_path, file_offset) in compressed_chunks.items():\n",
    "                if term <= chunk_key:\n",
    "                    compresssed_chunk_key = chunk_key\n",
    "                    break\n",
    "            \n",
    "            if compresssed_chunk_key is not None:\n",
    "                index_file_path = compressed_chunks[compresssed_chunk_key]['file_path']\n",
    "                data = read_data_from_index_file_compressed(offset - compressed_chunks[compresssed_chunk_key]['file_offset'], size, index_file_path)\n",
    "                term_data_dict[term] = data\n",
    "\n",
    "    return term_data_dict\n",
    "\n",
    "\n",
    "catalog_file_path = './stemmed_index_files/final_merged_catalog_file.txt'\n",
    "term_data_dict_compressed_chunks = process_query_compressed(all_query_terms, catalog_file_path, compressed_chunks)\n",
    "print(\"term_data_dict_compressed created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2b0cefb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_document_term_vectors_compressed_chunks = update_term_data_dict(term_data_dict_compressed_chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44a194f",
   "metadata": {},
   "source": [
    "# BM-25 using three compressed index chunk files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "445e6739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Query 85: corrupt public offici\n",
      "Processing Query 59: weather least locat\n",
      "Processing Query 56: prime lend rate prime rate\n",
      "Processing Query 71: incurs border guerrilla\n",
      "Processing Query 64: hostag\n",
      "Processing Query 62: coup attempt\n",
      "Processing Query 93: nation rifl associ nra\n",
      "Processing Query 99: iran contra affair\n",
      "Processing Query 58: rail strike rail strike\n",
      "Processing Query 77: poach wildlif\n",
      "Processing Query 54: agreement launch commerci satellit\n",
      "Processing Query 87: offic institut\n",
      "Processing Query 94: crime comput\n",
      "Processing Query 100: communist transfer technolog nation\n",
      "Processing Query 89: invest opec downstream\n",
      "Processing Query 61: israel iran contra affair\n",
      "Processing Query 95: comput crime\n",
      "Processing Query 68: safeti worker diamet fiber\n",
      "Processing Query 57: mci bell\n",
      "Processing Query 97: fiber optic technolog\n",
      "Processing Query 98: fiber optic\n",
      "Processing Query 60: salari incent pay pay\n",
      "Processing Query 80: 1988 presidenti\n",
      "Processing Query 63: machin translat\n",
      "Processing Query 91: weapon\n",
      "Queries executed successfully.\n"
     ]
    }
   ],
   "source": [
    "output_file_path = \"./result_files/output_BM25_Compressed_Chunks_Score.txt\"\n",
    "run_queries_and_write_results_bm25(output_file_path, query_dict, all_document_term_vectors_compressed_chunks)\n",
    "print(\"Queries executed successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01cfbc8b",
   "metadata": {},
   "source": [
    "# Proximity search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ad3a90b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_preprocessing_proximity(query):\n",
    "    query = process_content(query)\n",
    "    return query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0467caed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{85: 'allegations      corrupt public officials', 59: 'weather       least  fatality   location', 56: 'prime lending rate      prime rate', 71: 'incursions        border area     military forces   second    guerrilla     second', 64: 'result  politically  hostage taking', 62: 'military coup detat  attempted', 93: 'supporters   national rifle association nra', 99: 'development   iran contra affair', 58: 'rail strike    ongoing rail strike', 77: 'poaching method       wildlife', 54: 'contract   agreement       reservation  launch  commercial satellite', 87: 'current    officers   failed   institution', 94: 'crime    aid   computer', 100: 'non communist  states    transfer  high tech goods    technologies   nations', 89: 'investment   opec     downstream', 61: 'israel   iran contra affair', 95: 'computer application  crime', 68: 'concerns   safety  manufacturing    workers  fine diameter fibers      products', 57: 'mci      bell system', 97: 'fiber optics technology', 98: 'fiber optics equipment', 60: 'performance   salary   incentive pay     pay', 80: '1988 presidential candidate', 63: 'machine translation system', 91: 'weapons systems'}\n"
     ]
    }
   ],
   "source": [
    "query_dict_unmodified = {}\n",
    "query_file_path = \"../IR_data/AP_DATA/query_desc.51-100.short.txt\"\n",
    "\n",
    "with open(query_file_path, 'r') as query_desc_file:\n",
    "    queries = query_desc_file.readlines()\n",
    "\n",
    "for query_desc in queries:\n",
    "    query_desc = query_desc.strip()\n",
    "\n",
    "    if not query_desc:\n",
    "        continue\n",
    "\n",
    "    query_num, query_text = query_desc.split('.', 1)\n",
    "    query_num = int(query_num.strip())\n",
    "    query_text = query_preprocessing_proximity(' '.join(query_text.strip().split()))\n",
    "    query_dict_unmodified[query_num] = query_text.strip()\n",
    "print(query_dict_unmodified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ee696acc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['allegations', 'corrupt', 'public', 'officials', 'weather', 'least', 'fatality', 'location', 'prime', 'lending', 'rate', 'prime', 'rate', 'incursions', 'border', 'area', 'military', 'forces', 'second', 'guerrilla', 'second', 'result', 'politically', 'hostage', 'taking', 'military', 'coup', 'detat', 'attempted', 'supporters', 'national', 'rifle', 'association', 'nra', 'development', 'iran', 'contra', 'affair', 'rail', 'strike', 'ongoing', 'rail', 'strike', 'poaching', 'method', 'wildlife', 'contract', 'agreement', 'reservation', 'launch', 'commercial', 'satellite', 'current', 'officers', 'failed', 'institution', 'crime', 'aid', 'computer', 'non', 'communist', 'states', 'transfer', 'high', 'tech', 'goods', 'technologies', 'nations', 'investment', 'opec', 'downstream', 'israel', 'iran', 'contra', 'affair', 'computer', 'application', 'crime', 'concerns', 'safety', 'manufacturing', 'workers', 'fine', 'diameter', 'fibers', 'products', 'mci', 'bell', 'system', 'fiber', 'optics', 'technology', 'fiber', 'optics', 'equipment', 'performance', 'salary', 'incentive', 'pay', 'pay', '1988', 'presidential', 'candidate', 'machine', 'translation', 'system', 'weapons', 'systems']\n"
     ]
    }
   ],
   "source": [
    "all_query_terms_unmodified = []\n",
    "\n",
    "for text in query_dict_unmodified.values():\n",
    "    all_query_terms_unmodified.extend(text.split())\n",
    "\n",
    "print(all_query_terms_unmodified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7fd97a5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Term data dictionary created.\n"
     ]
    }
   ],
   "source": [
    "catalog_file_path_nonstemmed = './non_stemmed_index_files/final_merged_catalog_file.txt'\n",
    "index_file_path_nonstemmed = './non_stemmed_index_files/final_merged_index_file.txt'\n",
    "\n",
    "term_data_dict_unmodified = process_query(all_query_terms_unmodified, catalog_file_path_nonstemmed, index_file_path_nonstemmed)\n",
    "print(\"Term data dictionary created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8fe0e059",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_document_term_vectors_unmodified = update_term_data_dict(term_data_dict_unmodified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ecf289ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_preprocessing_unmodified_stemmed(query):\n",
    "    query = process_content(query)\n",
    "    query = stem_text(query, ps)\n",
    "    return query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "eac0e042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{85: 'alleg corrupt public offici', 59: 'weather least fatal locat', 56: 'prime lend rate prime rate', 71: 'incurs border area militari forc second guerrilla second', 64: 'result polit hostag take', 62: 'militari coup detat attempt', 93: 'support nation rifl associ nra', 99: 'develop iran contra affair', 58: 'rail strike ongo rail strike', 77: 'poach method wildlif', 54: 'contract agreement reserv launch commerci satellit', 87: 'current offic fail institut', 94: 'crime aid comput', 100: 'non communist state transfer high tech good technolog nation', 89: 'invest opec downstream', 61: 'israel iran contra affair', 95: 'comput applic crime', 68: 'concern safeti manufactur worker fine diamet fiber product', 57: 'mci bell system', 97: 'fiber optic technolog', 98: 'fiber optic equip', 60: 'perform salari incent pay pay', 80: '1988 presidenti candid', 63: 'machin translat system', 91: 'weapon system'}\n"
     ]
    }
   ],
   "source": [
    "query_dict_unmodified_stemmed = {}\n",
    "query_file_path = \"../IR_data/AP_DATA/query_desc.51-100.short.txt\"\n",
    "\n",
    "with open(query_file_path, 'r') as query_desc_file:\n",
    "    queries = query_desc_file.readlines()\n",
    "\n",
    "for query_desc in queries:\n",
    "    query_desc = query_desc.strip()\n",
    "\n",
    "    if not query_desc:\n",
    "        continue\n",
    "\n",
    "    query_num, query_text = query_desc.split('.', 1)\n",
    "    query_num = int(query_num.strip())\n",
    "    query_text = query_preprocessing_unmodified_stemmed(' '.join(query_text.strip().split()))\n",
    "    query_dict_unmodified_stemmed[query_num] = query_text.strip()\n",
    "print(query_dict_unmodified_stemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7ad4d61a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alleg', 'corrupt', 'public', 'offici', 'weather', 'least', 'fatal', 'locat', 'prime', 'lend', 'rate', 'prime', 'rate', 'incurs', 'border', 'area', 'militari', 'forc', 'second', 'guerrilla', 'second', 'result', 'polit', 'hostag', 'take', 'militari', 'coup', 'detat', 'attempt', 'support', 'nation', 'rifl', 'associ', 'nra', 'develop', 'iran', 'contra', 'affair', 'rail', 'strike', 'ongo', 'rail', 'strike', 'poach', 'method', 'wildlif', 'contract', 'agreement', 'reserv', 'launch', 'commerci', 'satellit', 'current', 'offic', 'fail', 'institut', 'crime', 'aid', 'comput', 'non', 'communist', 'state', 'transfer', 'high', 'tech', 'good', 'technolog', 'nation', 'invest', 'opec', 'downstream', 'israel', 'iran', 'contra', 'affair', 'comput', 'applic', 'crime', 'concern', 'safeti', 'manufactur', 'worker', 'fine', 'diamet', 'fiber', 'product', 'mci', 'bell', 'system', 'fiber', 'optic', 'technolog', 'fiber', 'optic', 'equip', 'perform', 'salari', 'incent', 'pay', 'pay', '1988', 'presidenti', 'candid', 'machin', 'translat', 'system', 'weapon', 'system']\n"
     ]
    }
   ],
   "source": [
    "all_query_terms_unmodified_stemmed = []\n",
    "\n",
    "for text in query_dict_unmodified_stemmed.values():\n",
    "    all_query_terms_unmodified_stemmed.extend(text.split())\n",
    "\n",
    "print(all_query_terms_unmodified_stemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "18320f84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Term data dictionary created.\n"
     ]
    }
   ],
   "source": [
    "catalog_file_path = './stemmed_index_files/final_merged_catalog_file.txt'\n",
    "index_file_path = './stemmed_index_files/final_merged_index_file.txt'\n",
    "\n",
    "term_data_dict_unmodified_stemmed = process_query(all_query_terms_unmodified_stemmed, catalog_file_path, index_file_path)\n",
    "print(\"Term data dictionary created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "299b558d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_document_term_vectors_unmodified_unstemmed = update_term_data_dict(term_data_dict_unmodified_stemmed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77222d5c",
   "metadata": {},
   "source": [
    "# Get min-span using sliding window algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c4c19046",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_proximity_score(min_span, ngram_length):\n",
    "    if ngram_length == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return math.pow(0.8, (min_span - ngram_length) / ngram_length)\n",
    "\n",
    "def get_min_span(query_proximity_dict):\n",
    "    if len(query_proximity_dict) == 0:\n",
    "        return -1\n",
    "    else:\n",
    "        tuples = []\n",
    "        for index, (key, postings) in enumerate(query_proximity_dict.items()):\n",
    "            for val in postings:\n",
    "                tuples.append((val, index, postings.index(val)))\n",
    "\n",
    "        tuples.sort()\n",
    "\n",
    "        window = [postings[0] for postings in query_proximity_dict.values()]\n",
    "        left = 0\n",
    "        min_span = float('inf')\n",
    "\n",
    "        for right in range(len(tuples)):\n",
    "            val, list_idx, _ = tuples[right]\n",
    "            window[list_idx] = val\n",
    "            \n",
    "            while left < len(window) and window[left] != min(window):\n",
    "                left += 1\n",
    "\n",
    "            if max(window) - min(window) < min_span:\n",
    "                min_span = max(window) - min(window)\n",
    "        return min_span"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13567377",
   "metadata": {},
   "source": [
    "# Proximity search on top of BM-25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "88e531ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from collections import defaultdict\n",
    "\n",
    "def calculate_okapi_bm25(tfwd, dfw, D, length_doc, avg_doc_length, tfwq, k1=1.2, b=0.75, k2=100):\n",
    "    term1 = math.log((D - dfw + 0.5) / (dfw + 0.5))\n",
    "    term2_num = (tfwd * (k1 + 1))\n",
    "    term2_den = (tfwd + k1 * ((1 - b) + (b * (length_doc / avg_doc_length))))\n",
    "    term3 = (tfwq + (k2 * tfwq)) / (tfwq + k2)\n",
    "    return term1 * (term2_num / term2_den) * term3\n",
    "\n",
    "def run_queries_and_write_results_bm25_PS(output_file, query_dict, total_unique_terms, all_document_term_vectors):\n",
    "    with open(output_file, 'w') as output:\n",
    "        for query_num, query_text in query_dict.items():\n",
    "            print(f\"Processing Query {query_num}: {query_text}\")\n",
    "\n",
    "            query_terms = query_text.split()\n",
    "            D = len(all_document_ids)  \n",
    "            document_scores = defaultdict(float)\n",
    "\n",
    "            for term in query_terms:\n",
    "                if term in all_document_term_vectors:\n",
    "                    document_term_vector = all_document_term_vectors[term]\n",
    "                    dfw = document_term_vector['doc_freq']\n",
    "                    avg_doc_length = sum(document_lengths.values()) / len(document_lengths)\n",
    "                    \n",
    "                    for doc_id, positions in document_term_vector['positions'].items():\n",
    "                        tfwd = len(positions)\n",
    "                        length_doc = document_lengths[all_document_ids[str(doc_id)]]\n",
    "                        tfwq = query_terms.count(term)\n",
    "                        \n",
    "                        bm25_score = calculate_okapi_bm25(tfwd, dfw, D, length_doc, avg_doc_length, tfwq)\n",
    "                        document_scores[doc_id] += bm25_score\n",
    "            \n",
    "            for doc_id in all_document_ids:\n",
    "                query_proximity_dict = {}\n",
    "                for term in query_terms:\n",
    "                    if term in all_document_term_vectors and int(doc_id) in all_document_term_vectors[term]['positions']:\n",
    "                        query_proximity_dict[term] = all_document_term_vectors[term]['positions'][int(doc_id)]\n",
    "                min_span = get_min_span(query_proximity_dict)\n",
    "                document_scores[int(doc_id)] += calculate_proximity_score(min_span, len(query_proximity_dict))\n",
    "\n",
    "            sorted_docs = sorted(document_scores.items(), key=lambda x: x[1], reverse=True)[:1000]\n",
    "\n",
    "            for rank, (doc_id, score) in enumerate(sorted_docs, start=1):\n",
    "                output.write(str(query_num) + ' Q0 ' + str(all_document_ids[str(doc_id)]) + ' ' + str(rank) + ' ' + str(score) + ' Exp'+\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985f27ae",
   "metadata": {},
   "source": [
    "# Running proximity search on top of BM-25 for unmodified unstemmed queries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7ac453c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Query 85: allegations      corrupt public officials\n",
      "Processing Query 59: weather       least  fatality   location\n",
      "Processing Query 56: prime lending rate      prime rate\n",
      "Processing Query 71: incursions        border area     military forces   second    guerrilla     second\n",
      "Processing Query 64: result  politically  hostage taking\n",
      "Processing Query 62: military coup detat  attempted\n",
      "Processing Query 93: supporters   national rifle association nra\n",
      "Processing Query 99: development   iran contra affair\n",
      "Processing Query 58: rail strike    ongoing rail strike\n",
      "Processing Query 77: poaching method       wildlife\n",
      "Processing Query 54: contract   agreement       reservation  launch  commercial satellite\n",
      "Processing Query 87: current    officers   failed   institution\n",
      "Processing Query 94: crime    aid   computer\n",
      "Processing Query 100: non communist  states    transfer  high tech goods    technologies   nations\n",
      "Processing Query 89: investment   opec     downstream\n",
      "Processing Query 61: israel   iran contra affair\n",
      "Processing Query 95: computer application  crime\n",
      "Processing Query 68: concerns   safety  manufacturing    workers  fine diameter fibers      products\n",
      "Processing Query 57: mci      bell system\n",
      "Processing Query 97: fiber optics technology\n",
      "Processing Query 98: fiber optics equipment\n",
      "Processing Query 60: performance   salary   incentive pay     pay\n",
      "Processing Query 80: 1988 presidential candidate\n",
      "Processing Query 63: machine translation system\n",
      "Processing Query 91: weapons systems\n",
      "Queries executed successfully.\n"
     ]
    }
   ],
   "source": [
    "output_file_path = \"./result_files/output_ProximitySearch_Unstemmed_Unmodified_Score.txt\"\n",
    "run_queries_and_write_results_bm25_PS(output_file_path, query_dict_unmodified, total_unique_terms, all_document_term_vectors_unmodified)\n",
    "print(\"Queries executed successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0466599",
   "metadata": {},
   "source": [
    "# Running proximity search on top of BM-25 for modified unstemmed queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bda7d7dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Query 85: corrupt public officials\n",
      "Processing Query 59: weather least location\n",
      "Processing Query 56: prime lending rate prime rate\n",
      "Processing Query 71: incursions border guerrilla\n",
      "Processing Query 64: hostage\n",
      "Processing Query 62: coup attempted\n",
      "Processing Query 93: national rifle association nra\n",
      "Processing Query 99: iran contra affair\n",
      "Processing Query 58: rail strike rail strike\n",
      "Processing Query 77: poaching wildlife\n",
      "Processing Query 54: agreement launch commercial satellite\n",
      "Processing Query 87: officers institution\n",
      "Processing Query 94: crime computer\n",
      "Processing Query 100: communist transfer technologies nations\n",
      "Processing Query 89: investment opec downstream\n",
      "Processing Query 61: israel iran contra affair\n",
      "Processing Query 95: computer crime\n",
      "Processing Query 68: safety workers diameter fibers\n",
      "Processing Query 57: mci bell\n",
      "Processing Query 97: fiber optics technology\n",
      "Processing Query 98: fiber optics\n",
      "Processing Query 60: salary incentive pay pay\n",
      "Processing Query 80: 1988 presidential\n",
      "Processing Query 63: machine translation\n",
      "Processing Query 91: weapons\n",
      "Queries executed successfully.\n"
     ]
    }
   ],
   "source": [
    "output_file_path = \"./result_files/output_ProximitySearch_Unstemmed_Modified_Score.txt\"\n",
    "run_queries_and_write_results_bm25_PS(output_file_path, query_dict_unstemmed, total_unique_terms, all_document_term_vectors_unstemmed)\n",
    "print(\"Queries executed successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b6ff34",
   "metadata": {},
   "source": [
    "# Running proximity search on top of BM-25 for unmodified stemmed queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "54b76e4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Query 85: alleg corrupt public offici\n",
      "Processing Query 59: weather least fatal locat\n",
      "Processing Query 56: prime lend rate prime rate\n",
      "Processing Query 71: incurs border area militari forc second guerrilla second\n",
      "Processing Query 64: result polit hostag take\n",
      "Processing Query 62: militari coup detat attempt\n",
      "Processing Query 93: support nation rifl associ nra\n",
      "Processing Query 99: develop iran contra affair\n",
      "Processing Query 58: rail strike ongo rail strike\n",
      "Processing Query 77: poach method wildlif\n",
      "Processing Query 54: contract agreement reserv launch commerci satellit\n",
      "Processing Query 87: current offic fail institut\n",
      "Processing Query 94: crime aid comput\n",
      "Processing Query 100: non communist state transfer high tech good technolog nation\n",
      "Processing Query 89: invest opec downstream\n",
      "Processing Query 61: israel iran contra affair\n",
      "Processing Query 95: comput applic crime\n",
      "Processing Query 68: concern safeti manufactur worker fine diamet fiber product\n",
      "Processing Query 57: mci bell system\n",
      "Processing Query 97: fiber optic technolog\n",
      "Processing Query 98: fiber optic equip\n",
      "Processing Query 60: perform salari incent pay pay\n",
      "Processing Query 80: 1988 presidenti candid\n",
      "Processing Query 63: machin translat system\n",
      "Processing Query 91: weapon system\n",
      "Queries executed successfully.\n"
     ]
    }
   ],
   "source": [
    "output_file_path = \"./result_files/output_ProximitySearch_Stemmed_Unmodified_Score.txt\"\n",
    "run_queries_and_write_results_bm25_PS(output_file_path, query_dict_unmodified_stemmed, total_unique_terms, all_document_term_vectors_unmodified_unstemmed)\n",
    "print(\"Queries executed successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e0dd13",
   "metadata": {},
   "source": [
    "# Running proximity search on top of BM-25 for modified stemmed queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c3224426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Query 85: corrupt public offici\n",
      "Processing Query 59: weather least locat\n",
      "Processing Query 56: prime lend rate prime rate\n",
      "Processing Query 71: incurs border guerrilla\n",
      "Processing Query 64: hostag\n",
      "Processing Query 62: coup attempt\n",
      "Processing Query 93: nation rifl associ nra\n",
      "Processing Query 99: iran contra affair\n",
      "Processing Query 58: rail strike rail strike\n",
      "Processing Query 77: poach wildlif\n",
      "Processing Query 54: agreement launch commerci satellit\n",
      "Processing Query 87: offic institut\n",
      "Processing Query 94: crime comput\n",
      "Processing Query 100: communist transfer technolog nation\n",
      "Processing Query 89: invest opec downstream\n",
      "Processing Query 61: israel iran contra affair\n",
      "Processing Query 95: comput crime\n",
      "Processing Query 68: safeti worker diamet fiber\n",
      "Processing Query 57: mci bell\n",
      "Processing Query 97: fiber optic technolog\n",
      "Processing Query 98: fiber optic\n",
      "Processing Query 60: salari incent pay pay\n",
      "Processing Query 80: 1988 presidenti\n",
      "Processing Query 63: machin translat\n",
      "Processing Query 91: weapon\n",
      "Queries executed successfully.\n"
     ]
    }
   ],
   "source": [
    "output_file_path = \"./result_files/output_ProximitySearch_Stemmed_Modified_Score.txt\"\n",
    "run_queries_and_write_results_bm25_PS(output_file_path, query_dict, total_unique_terms, all_document_term_vectors)\n",
    "print(\"Queries executed successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e97958a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
